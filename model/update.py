from model import CGD
from dataset import CommerceImageDataset
import torch
from torch.utils.data import DataLoader
import pandas as pd
from tqdm import tqdm
from elasticsearch import Elasticsearch, helpers


def updateData(data_dict : dict): #data_dict = {"{item_no}" : vector}
    index="hyreco512"
    
    keys = list(data_dict.keys())
    
    for i in tqdm(range(len(data_dict))):
        _id = keys[i] # id = item_no
        body = {
            'doc':{"retrieval_vector" : data_dict[_id]}
        }
            
        client.update(index=index, id=_id, body=body)
    
    client.indices.refresh(index=index)

if __name__ == '__main__':
    print("load model...")
    batch_size = 50
    commerce_batch_size = 35

    commerce_dataset = CommerceImageDataset()
    commerce_data_loader = DataLoader(commerce_dataset, commerce_batch_size, shuffle=False)
    eval_dict = {'commerce': {'data_loader': commerce_data_loader}}

    backbone_type = 'resnet_50'
    gd_config = "MG"
    feature_dim = 512
    smoothing = 0.1
    temperature = 0.5
    margin = 0.1
    recalls =[1,2,4,8]
    num_epochs = 20
    num_classes = 7983
    save_name_pre = 'results/{}_{}_{}_{}_{}_{}'.format("clothes", backbone_type, gd_config, feature_dim, margin, batch_size)
    path = save_name_pre + '_model.pth'

    model = CGD(backbone_type, gd_config, feature_dim, num_classes=num_classes)
    model.load_state_dict(torch.load(path))
    model.eval()
    print("load model complete")
    print("----------------------")

    print("extract features...")
    commerce_features = {}
    commerce_length = len(commerce_dataset) // commerce_batch_size
    total = 0

    commerce_data_bar = tqdm(commerce_data_loader)
    with torch.no_grad():
        for inputs, paths in commerce_data_bar:
            features, _ = model(inputs)
            
            for i in range(commerce_batch_size):
                commerce_features[paths[i][14:]] = features[i]
        
            total += 1
            commerce_data_bar.set_description('extract_features {}/{}'.format(total,commerce_length))

    print("save csv file...")
    keys = list(commerce_features.keys())
    for key in tqdm(keys):
        commerce_features[key] = commerce_features[key].tolist()

    commerce_df = pd.DataFrame.from_dict(commerce_features, orient='index')

    pd.DataFrame.to_csv(commerce_df,'commerce_img_features.csv')
    print("save csv file complete")
    print("----------------------")

    print("load csv file...")
    commerce_df = pd.read_csv("commerce_img_features.csv")
    commerce_id = pd.read_csv("commerce_data/sampled_products.csv")
    commerce_id = commerce_id.loc[:,["item_no","image_name"]]
    commerce_id = commerce_id.drop(commerce_id[commerce_id['image_name'] == "10ec6bea769ac095743a9455ae069981"].index) #error image
    commerce_joint = {}
    for item_id in commerce_id.iloc[:,1]:
        commerce_joint[item_id] = commerce_df[commerce_df.iloc[:,0]==item_id].iloc[:,1:].values.tolist()[0]

    print("Upload to Elastic Search")
    # Password for the 'elastic' user generated by Elasticsearch
    ELASTIC_PASSWORD = ""

    # Found in the 'Manage Deployment' page
    CLOUD_ID = ""

    # Create the client instance
    client = Elasticsearch(
        cloud_id=CLOUD_ID,
        basic_auth=("elastic", ELASTIC_PASSWORD)
    )

    print("Login :",client.info())

    updateData(commerce_joint)
